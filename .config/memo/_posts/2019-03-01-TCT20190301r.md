# TCT20190301

【サマリー】
東京海上日動様は次期システムの構築に伴い、MQの導入を検討されております。
次期システムは、z/OS上のIMSから分散サーバーのODSにデータをレプリケーションするもので、z/OSと分散サーバー間のデータの受け渡しにMQが使用されます。
今回のTCTでは、事前に頂いた質問についてお答えしました。

【アクション事項】
申込者側: 特にありません
担当者側: 特にありません

- バージョン等
	z/OS 2.1
	MQ for z/OS V8.0
	RHEL V7.6
	WMQ 未定

- 非機能要件
・運用
	24/365
	有事 RPO オンライン1分、RTO 24h
・メッセージサイズ
	大多数 100KB～1MB程度 ?
	最大    200MB程度、2MBずつに分けてMQ PUTの見込み(グループ化)

[ご質問事項詳細]

1. ホスト側連携BMPは同質の処理であるため、自然にはすべて同じQに対してのMQ PUTとしたい気がします。
ただ、同じ連携BMPからは同じQに届けたいという今回の要件の場合、同名QではNGで、Q名をそれぞれ別にしないといけないしょうか。

	ホストと分散のキューが1:1対応である必要があり、順序保証が必要である場合、キューの名前をそれぞれ別の名称にする必要があるため、クラスタ構成にするメリットはあまりありません。

	また、キューマネージャーがキューごとに存在する場合には、同じクラスタに属していなければ、キューの名前にすることはできます。

2. ご質問1 = YESの場合、可用性を向上させるためにどのような構成が考えられるでしょうか。

	N/A
	(補足)
	障害時、もとのキューにメッセージが滞留したまま別のキューで処理を続行しようとすると、トランザクションの整合性が取れなくなるため、図のような構成は、要件にそぐわなくなる可能性が高いと思われます。

3. ホストQMGR ABNEDや、MQ PUT ERRORとなった場合、連携用BMPバッチを別LPARで稼動させ別IMS-QMGRで動かそうと思います。
何か、こういうケースで効果あり、というようなシナリオがありましたら
ご教示ください。

	キューマネージャーの再起動を待つのが一般的です。
	また、別LPARでの起動に関する考慮点は質問2と同様です。
	キューフルの場合、問題はチャネルか宛先キュー、宛先キューマネージャーにあるため、z/OSのキューマネージャーを別LPARで立ち上げても問題は解決しません。
	運用監視の面でもどう対応するかを考慮する必要があります。

4-1.オープン側のQが2つのクラスターQとなることになりますが構成として問題ないでしょうか。

	問題ありません。

4-2. Qのアンロード/ロードで引き継ぐような運用が可能と考えておいてよいでしょうか。

	計画停止ではトランスミッションキューを空にしてからキューマネージャーを停止するのが一般的です。

	キューの中身をアンロードし、別のキューマネージャーのトランスミッションキューにロードすることは理論上は可能であると思われます。

	以下に、ユーティリティのマニュアルを添付します


````````````
ユーティリティのマニュアル添付


``````````````

5. ホスト側には一部長時間オンラインTRXがあります。数十分かかり、DB更新量したがって連携データも200MB弱になる想定です。
”かるい”TRXへの影響を排除する意味で、”経路”を分けたいと思っています。(差分DB、連携BMP、あて先Q)
デフォルトだとホストMQ側のトランスミットキューは同じになってしまうと思いますが、ここも分けるなどしておいたほうがよいでしょうか。

N/A


6-1. ホストMQではメッセージのセグメント化はできなかったように記憶していたのですが、今もできないでよかったでしょうか。

はい。

6-2. 当初、Qサイズが膨大になるという想定もあり、64GBページセットにしないといけない、ということも考えていたのですが、仮に採用するとした場合、パフォーマンス以外に何か懸念はあったりするものでしょうか

こちらで認識している限りでは拡張ページセットに関して、特別な考慮点はありません


以上です。




``````````````
メモ

　松本さんがおっしゃっていたと記憶しているのですが、オブジェクト記述子 MQODとメッセージグループを利用すればクラスタ構成でも1:1対応ができて、かつ順序保証も可能なのでしょうか？
https://www.ibm.com/developerworks/jp/websphere/library/wmq/toranomaki/11.html





3.
質問

1. クラスタにしてホスト側とアプライ側のキュー名を同じにしたい



クラスタを組んで、グループメッセージだけをグループに送るようにする


アプリケーションが、証券番号の順序保証するならできる



さぶんDB には証券番号単位で順序保証されたデータが入っている
ので差分DB→MQは一経路だけでやる

負荷分散はむり

その場合同名のキューはむり





現行システムからデータをレプリケーションしたい

ODSにzosからデータを持ってくる

更新情報を差分DBに保存して、それをMQで飛ばしてODSを更新


1UOWは1トランザクション
複数DB更新があってそれが送る長くなるから、メッセージを分割する


トランザクション内の順序性、トランザクション間の保険証券番号の順序性ももとめられる


複数のDBの更新の順序性はもとめられる

ODSには断面が保存される
LPARは6系統　一LPARに１QMGR

手組みでレプリケーションを行いたい

トランザクション単位でまとめてputしたい


更新順序は、単一の対象に関しては順序を守りたいけど
それ以外はどうでもいい
10秒以内に反映
サイズ
1000k~1M
max200M
2m以上は2mごとに分割して送信(何かのアプリつかう)

24/365
PRO一分
PTO24h
ゼット　ｚOSV2,1 MQ V8
RHEL　V7.6 V9.1(未定)


アプライプロセスはETLサーバーに
ETLサーバーがODSを更新

さぶんDBはロック競合軽減のためにたくさん作る


クラスタにしたい(意味は特にない)


質問

1. クラスタにしてホスト側とアプライ側のキュー名を同じにしたい



クラスタを組んで、グループメッセージだけをグループに送るようにする


アプリケーションが、証券番号の順序保証するならできる



さぶんDB には証券番号単位で順序保証されたデータが入っている
ので差分DB→MQは一経路だけでやる

負荷分散はむり

その場合同名のキューはむり


オープンMQ

1. クラスタ+MIQMGR
　MQで順序保証できないよ
	オープン側の復旧要件が1分以内で、MIQMGR

2. MIQMGR
	MIQMGRでおくる

名前を分ける場合は、クラスタとリモートキューの違いはない


クラスタだけだと、障害が起きたところに貯まるし、経路がかわってしまう




1. 可用性 MIQMGR＋クラスタ

だめになったキューに残ったメッセージがあれば移行しても意味がない(トランザクションが保証されない)

からクラスタでやる意味ないかな


MIQMGRで可用性を高める方向性


1. ホスト側のQMGRが何らかの障害が起きた場合、違うLPARを立てて継続できるか
- さっきと同様にやる意味がない
- 全体的な監視を考えるべき
1. 複数のクラスタにしょぞくすることはできるのか
- 可能
1. 何らかの障害でQに滞留したまま、メインCenterが落ちてしまった、サブセンターを開始しなくてはならない場合、溜まったキューをどう処理したらよいか
- 普通はそんなことしない
- あとでメッセージをアンロードするユーティリティをつたえる


1. その他
- 質問後5  N/A
-
- ホストメッセージのセグメント化はできない
- 拡張ページセットに関しては特に考慮点なし
-





サーバーの範囲で
